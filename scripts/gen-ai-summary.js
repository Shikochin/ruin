#!/usr/bin/env node
import fs from 'fs'
import path from 'path'
import matter from 'gray-matter'
import OpenAI from 'openai'
import { glob } from 'glob'

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
    baseURL: process.env.OPENAI_API_BASE || 'https://api.openai.com/v1',
})

async function generateSummary(content) {
    const prompt = `è¯·ä¸ºä»¥ä¸‹æ–‡ç« å†™ä¸€ä¸ªç®€çŸ­çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼Œä¸­æ–‡ï¼‰ï¼š\n\n${content}`
    const response = await openai.chat.completions.create({
        model: 'gemini-2.5-pro',
        messages: [{ role: 'user', content: prompt }],
    })
    return response.choices[0].message.content.trim()
}

async function main() {
    const files = glob.sync('source/_posts/**/*.md')

    for (const filePath of files) {
        if (!filePath.endsWith('.md')) continue
        const raw = fs.readFileSync(filePath, 'utf-8')
        const parsed = matter(raw)

        if (parsed.data.summary) {
            console.log(`âœ… ${filePath} å·²æœ‰æ‘˜è¦ï¼Œè·³è¿‡`)
            continue
        }

        console.log(`ðŸ“ æ­£åœ¨ä¸º ${filePath} ç”Ÿæˆæ‘˜è¦...`)
        const summary = await generateSummary(parsed.content)
        parsed.data.summary = summary

        fs.writeFileSync(filePath, matter.stringify(parsed), 'utf-8')
        console.log(`âœ¨ å·²ç”Ÿæˆæ‘˜è¦: ${summary}`)
    }
}

main().catch((err) => {
    console.error(err)
    process.exit(1)
})
